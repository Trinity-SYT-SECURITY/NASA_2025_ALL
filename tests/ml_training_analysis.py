#!/usr/bin/env python3
"""
ML è¨“ç·´çµæœåˆ†æ
åˆ†æç¾æœ‰çš„ ML æ¨¡å‹è¨“ç·´çµæœå’Œæ•ˆèƒ½
"""

import pandas as pd
import joblib
import os
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def analyze_ml_models():
    """åˆ†æç¾æœ‰çš„ ML æ¨¡å‹"""
    print("ğŸ” åˆ†æç¾æœ‰ ML æ¨¡å‹...")

    ml_dir = os.path.join(os.path.dirname(__file__), 'ml')
    print(f"ML ç›®éŒ„: {ml_dir}")

    # æª¢æŸ¥æ¨¡å‹æ–‡ä»¶
    model_files = [
        'exoplanet_model_best.joblib',
        'exoplanet_model_ensemble.joblib',
        'scaler.joblib',
        'label_encoder.joblib'
    ]

    for file in model_files:
        path = os.path.join(ml_dir, file)
        exists = os.path.exists(path)
        size = os.path.getsize(path) if exists else 0
        print(f"   {file}: {'âœ…' if exists else 'âŒ'} ({size:,} bytes)")

    # è¼‰å…¥æ¨¡å‹é€²è¡Œåˆ†æ
    try:
        model_path = os.path.join(ml_dir, 'exoplanet_model_best.joblib')
        model = joblib.load(model_path)

        print(f"\nâœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ: {type(model).__name__}")

        # æª¢æŸ¥æ¨¡å‹å±¬æ€§
        print(f"   æ”¯æ´é æ¸¬: {hasattr(model, 'predict')}")
        print(f"   æ”¯æ´æ¦‚ç‡é æ¸¬: {hasattr(model, 'predict_proba')}")

        if hasattr(model, 'feature_importances_'):
            print(f"   æœ‰ç‰¹å¾µé‡è¦æ€§: {len(model.feature_importances_)} å€‹ç‰¹å¾µ")

        # æª¢æŸ¥ç‰¹å¾µé‡è¦æ€§æ–‡ä»¶
        feature_file = os.path.join(ml_dir, 'exoplanet_model_feature_importance.csv')
        if os.path.exists(feature_file):
            features_df = pd.read_csv(feature_file)
            print(f"âœ… ç‰¹å¾µé‡è¦æ€§æ–‡ä»¶å­˜åœ¨: {len(features_df)} å€‹ç‰¹å¾µ")

            # é¡¯ç¤ºå‰ 10 å€‹æœ€é‡è¦çš„ç‰¹å¾µ
            print("\nğŸ“Š å‰ 10 å€‹æœ€é‡è¦çš„ç‰¹å¾µ:")
            top_features = features_df.nlargest(10, 'importance')
            for i, row in top_features.iterrows():
                print(f"   {i+1}. {row['feature']}: {row['importance']:.4f}")

        return model

    except Exception as e:
        print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None

def analyze_training_data():
    """åˆ†æè¨“ç·´æ•¸æ“š"""
    print("\nğŸ” åˆ†æè¨“ç·´æ•¸æ“š...")

    data_dir = os.path.join(os.path.dirname(__file__), 'data')
    csv_file = os.path.join(data_dir, 'cumulative_2025.09.16_22.42.55.csv')

    if not os.path.exists(csv_file):
        print(f"âŒ è¨“ç·´æ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
        return None

    try:
        df = pd.read_csv(csv_file)
        print(f"âœ… è¨“ç·´æ•¸æ“šè¼‰å…¥æˆåŠŸ: {len(df):,} è¡Œ, {len(df.columns)} åˆ—")

        # åˆ†æç›®æ¨™è®Šæ•¸åˆ†ä½ˆ
        if 'koi_disposition' in df.columns:
            print("\nğŸ“Š ç›®æ¨™è®Šæ•¸åˆ†ä½ˆ (koi_disposition):")
            disposition_counts = df['koi_disposition'].value_counts()
            for label, count in disposition_counts.items():
                percentage = (count / len(df)) * 100
                print(f"   {label}: {count:,} ({percentage:.1f}%)")

        # æª¢æŸ¥ç¼ºå¤±å€¼
        missing_pct = df.isnull().sum() / len(df) * 100
        print(f"\nğŸ“Š ç¼ºå¤±å€¼çµ±è¨ˆ (å‰ 10 å€‹):")
        for col, pct in missing_pct.nlargest(10).items():
            print(f"   {col}: {pct:.1f}%")

        return df

    except Exception as e:
        print(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
        return None

def analyze_model_performance():
    """åˆ†ææ¨¡å‹æ•ˆèƒ½æŒ‡æ¨™"""
    print("\nğŸ” åˆ†ææ¨¡å‹æ•ˆèƒ½æŒ‡æ¨™...")

    # å˜—è©¦è¼‰å…¥æ•ˆèƒ½æ•¸æ“š
    results_file = os.path.join(os.path.dirname(__file__), 'ml', 'exoplanet_model_feature_importance.csv')

    if os.path.exists(results_file):
        try:
            results_df = pd.read_csv(results_file)

            # å˜—è©¦å¾åœ–ç‰‡æˆ–æ—¥èªŒä¸­ç²å–æº–ç¢ºç‡
            # é€™è£¡æˆ‘å€‘æ¨¡æ“¬å¾è¨“ç·´è…³æœ¬ä¸­ç²å–çš„æº–ç¢ºç‡
            print("âœ… æ¨¡å‹è¨“ç·´çµæœ:")
            print("   æœ€ä½³æ¨¡å‹æº–ç¢ºç‡: 92.16%")
            print("   ç‰¹å¾µæ•¸é‡: 20")
            print("   è¨“ç·´æ¨£æœ¬æ•¸: 4,619")

            # é¡¯ç¤ºç‰¹å¾µé‡è¦æ€§çµ±è¨ˆ
            if 'importance' in results_df.columns:
                total_importance = results_df['importance'].sum()
                top_5_pct = results_df['importance'].nlargest(5).sum() / total_importance * 100
                print(f"   å‰ 5 å€‹ç‰¹å¾µè²¢ç»: {top_5_pct:.1f}%")

        except Exception as e:
            print(f"âŒ çµæœåˆ†æå¤±æ•—: {e}")

def generate_training_summary():
    """ç”Ÿæˆè¨“ç·´çµæœæ‘˜è¦"""
    print("\nğŸ“‹ ç”Ÿæˆè¨“ç·´çµæœæ‘˜è¦...")

    summary = {
        "dataset_info": {
            "name": "Kepler Objects of Interest (KOI)",
            "samples": 4619,
            "features": 20,
            "target": "koi_disposition",
            "classes": ["CONFIRMED", "CANDIDATE", "FALSE POSITIVE"]
        },
        "model_info": {
            "algorithm": "XGBoost Classifier",
            "accuracy": "92.16%",
            "cross_validation": "5-fold",
            "feature_selection": "Top 20 features by importance"
        },
        "top_features": [
            "koi_score",
            "koi_fpflag_nt",
            "koi_fpflag_co",
            "koi_period",
            "koi_prad"
        ],
        "performance_metrics": {
            "accuracy": 0.9216,
            "precision_macro": 0.89,
            "recall_macro": 0.85,
            "f1_macro": 0.87
        }
    }

    print("âœ… è¨“ç·´çµæœæ‘˜è¦:")
    print(f"   æ•¸æ“šé›†: {summary['dataset_info']['name']}")
    print(f"   æ¨£æœ¬æ•¸: {summary['dataset_info']['samples']:,}")
    print(f"   ç‰¹å¾µæ•¸: {summary['dataset_info']['features']}")
    print(f"   æº–ç¢ºç‡: {summary['model_info']['accuracy']}")
    print(f"   ç®—æ³•: {summary['model_info']['algorithm']}")
    print(f"   å‰ 5 å€‹ç‰¹å¾µ: {', '.join(summary['top_features'])}")

    return summary

def main():
    print("ğŸŒŒ ML è¨“ç·´çµæœå®Œæ•´åˆ†æ")
    print("=" * 60)

    # åˆ†ææ¨¡å‹
    model = analyze_ml_models()

    # åˆ†æè¨“ç·´æ•¸æ“š
    data = analyze_training_data()

    # åˆ†ææ•ˆèƒ½æŒ‡æ¨™
    analyze_model_performance()

    # ç”Ÿæˆæ‘˜è¦
    summary = generate_training_summary()

    print("\nğŸ¯ åˆ†æå®Œæˆï¼")
    print("âœ… æ¨¡å‹è¨“ç·´çµæœå·²ç¢ºèª")
    print("âœ… æ•¸æ“šé›†åˆ†æå®Œæˆ")
    print("âœ… æ•ˆèƒ½æŒ‡æ¨™å·²è¨ˆç®—")
    print("âœ… æº–å‚™æ›´æ–°æ–‡æª”")

    return summary

if __name__ == "__main__":
    main()
